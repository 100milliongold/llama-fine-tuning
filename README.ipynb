{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19929fe",
   "metadata": {},
   "source": [
    "# LLaMA3 Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7a1ee",
   "metadata": {},
   "source": [
    "1. 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105733bc1e9e444a972812f0f85dadce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "namuwiki_20210301_v3.parquet:   0%|          | 0.00/2.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"heegyu/namuwiki-extracted\" , cache_dir=\"/datasets/\")\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527501cd",
   "metadata": {},
   "source": [
    "2. 모델 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ab91c",
   "metadata": {},
   "source": [
    "| 구분         | 모델 (Model)                                          | 토크나이저 (Tokenizer)                                              |\n",
    "| ---------- | --------------------------------------------------- | -------------------------------------------------------------- |\n",
    "| **역할**     | 입력된 토큰을 기반으로 예측·생성·분류 등을 수행하는 핵심 AI 엔진              | 텍스트를 모델이 이해할 수 있는 토큰 단위로 변환하고, 반대로 토큰을 텍스트로 복원                 |\n",
    "| **입력/출력**  | 입력: 토큰 시퀀스<br>출력: 확률 분포, 다음 토큰, 임베딩 등               | 입력: 문자열<br>출력: 토큰 ID 시퀀스 및 주석 정보                               |\n",
    "| **구성 요소**  | 신경망(Transformer, LSTM, CNN 등), 레이어, 파라미터(가중치)로 이루어짐 | 규칙 기반(BPE, WordPiece, SentencePiece 등) 알고리즘과 단어 사전(Vocabulary) |\n",
    "| **학습 내용**  | 의미, 문맥, 패턴, 언어 구조 등을 학습                             | 자주 나타나는 텍스트 조각 단위를 효율적으로 분리하는 규칙을 학습                           |\n",
    "| **학습 대상**  | 대규모 텍스트의 문맥적 의미                                     | 텍스트의 통계적 구성(서브워드 단위 빈도 등)                                      |\n",
    "| **결과물**    | 문장 생성, 번역, 요약, 추론 등 자연어 처리 기능 수행                    | 토큰 리스트 생성 및 디토크나이징                                             |\n",
    "| **변경 영향**  | 모델 구조/파라미터 변경 시 성능에 직접적인 큰 변화 발생                    | 토크나이저 변경 시 토큰 분포가 바뀌어 모델 성능에 큰 영향 가능                           |\n",
    "| **독립성 여부** | 토크나이저가 만들어낸 토큰 단위에 의존해야 함                           | 모델 없이도 사용할 수 있지만 대부분 모델과 쌍으로 설계됨                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15beebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers 라이브러리를 사용한 모델 다운로드\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "model_name = \"meta-llama/Llama-4-Scout-17B-16E\"\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")  # 먼저 환경변수 확인\n",
    "if not hf_token:\n",
    "    print(\"Hugging Face 토큰을 입력하세요:\")\n",
    "    print(\"토큰 발급: https://huggingface.co/settings/tokens\")\n",
    "    hf_token = getpass(\"HF Token: \")\n",
    "\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"✅ Hugging Face 로그인 성공!\")\n",
    "else:\n",
    "    print(\"❌ 경고: 토큰이 입력되지 않았습니다.\")\n",
    "\n",
    "# 모델 다운로드\n",
    "print(f\"모델 다운로드 중: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"/models\", token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"/models\", token=hf_token)\n",
    "\n",
    "print(\"다운로드 완료!\")\n",
    "print(f\"Tokenizer: {tokenizer}\")\n",
    "print(f\"Model: {type(model)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
