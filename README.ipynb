{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19929fe",
   "metadata": {},
   "source": [
    "# LLaMA4 Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7a1ee",
   "metadata": {},
   "source": [
    "1. 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0924121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6437e1dd78ec40b3b9e1b599b1c0ec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "namuwiki_20210301_v3.parquet:   0%|          | 0.00/2.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb9b6df51d54b5aba5490d712c773b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/565293 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '!!아앗!!', 'text': '！！ああっと！！\\n▲신 세계수의 미궁 2에서 뜬 !!아앗!!\\n세계수의 미궁 시리즈에 전통으로 등장하는 대사. 2편부터 등장했으며 훌륭한 사망 플래그의 예시이다.\\n세계수의 모험가들이 탐험하는 던전인 수해의 구석구석에는 채취/벌채/채굴 포인트가 있으며, 이를 위한 채집 스킬에 투자하면 제한된 채집 기회에서 보다 큰 이득을 챙길 수 있다. 그러나 분배할 수 있는 스킬 포인트는 한정되어 있기 때문에 채집 스킬에 투자하는 만큼 전투 스킬 레벨은 낮아지게 된다. !!아앗!!이 발생하는 과정을 요약하면 다음과 같다.\\n다만 채집 시스템은 신 세계수 시리즈의 그리모어 복제, 복합 채집 스킬인 야생의 감, 5편의 종족 특유 스킬, 크로스의 1레벨이 만렙인 채집 스킬 등으로 편의성이 점차 나아져서 채집 스킬 때문에 스킬 트리가 내려가는 일은 점점 줄어들었다.\\n채집용 캐릭터들로 이루어진 약한 파티(ex: 레인저 5명)가 수해에 입장한다.\\n필드 전투를 피해 채집 포인트에 도착한 후 열심히 아이템을 캐는 중에...\\n!!아앗!!\\n라플레시아가 나타났다!\\n이때 등장하는 것은 FOE는 아니지만 훨씬 위층에 등장하는 강력한 필드 몬스터이며 선제 공격을 당하게 된다!\\n으앙 죽음(hage)\\n여담으로 !!아앗!!의 유래는 1인칭 던전 크롤러의 원조 위저드리에서 함정을 건드렸을 때 나오는 대사 Oops!(おおっと！)라고 한다.\\n!!아앗!!의 악랄함은 첫 등장한 작품이자 시리즈 중에서도 불친절하기로 정평이 난 2편이 절정이었다. 그야말로 위의 !!아앗!! 시퀀스 그대로, 묻지도 따지지도 않고 채집할 때마다 일정 확률로 강제로 전투에 돌입해야 했다. 게다가 이럴 때 쓰라고 있는 레인저의 스킬 \\'위험 감지(중간 확률로 적의 선제 공격을 무효화)\\'는 정작 작동하지 않는다!\\n참고로 2편에서 채집 도중 !!아앗!!이 뜰 확률은 고작 1%다. 낮아 보이는 확률이어도 플레이 중 한 번이라도 일어나는 것을 경험하는 체감 확률을 고려하여 확률을 설정한다고.\\n다행히 채집 중 낮은 확률로 \"좋은 아이템을 얻을 수 있을 것 같지만... 주변에서 몬스터들의 기척이 느껴진다.\"는 메시지가 뜨고 이때 운이 좋으면 레어 아이템을 얻을 수 있지만 반대의 경우 적과 싸우게 되는 것으로 조정되었다.\\n기본적인 것은 3편과 같지만, 4편에서는 움직이지 않고 채집할 때도 턴이 경과하도록 조정되었기 때문에 주변에 있는 FOE를 잊고 채집에 몰두하다가 FOE와 부딪히면 FOE 버전 !!아앗!!이 뜬다. 그리고 난이도 CASUAL로 플레이시, FOE로 인한 !!아앗!!을 제외하면 절대로 발생하지 않는다.\\n채집 방식이 한 턴으로 끝나는 구조로 바뀐 덕분인지 강제 조우로 다시 회귀해버렸다(...). 그나마 위험 감지 먹통과 같은 버그성 난점들은 수정되었다. 그 이후에 나온 세계수의 미궁 5 오랜 신화의 끝과 시리즈의 집대성 작품이자 3DS 마지막 작품인 세계수의 미궁 X도 마찬가지.\\n채집으로 한 번 아이템을 획득하면 \"다시, (채집 스킬)에 의해...\"가 뜨면서 한꺼번에 획득되는 구조.\\n본작의 채집은 신 세계수 시리즈와 같은 매커니즘이라 굳이 언급할 필요는 없으나, 퀘스트중에 2편의 !!아앗!! 시퀀스를 재현하면서 라플레시아가 등장하는 퀘스트가 존재한다.(...) 깨알같이 시스템 메세지 창이 아니라 대화창을 이용해서 완벽 재현한 것이 포인트.\\n세계수 시스템을 기반으로 한 페르소나 시리즈와의 콜라보 작품인 페르소나 Q에서도 등장한다. 3, 4편과 같이 파워 스폿에서 채집 도중 메시지가 뜨며, 실패하면 파티에 참가하고 있는 멤버 중 한 명의 !!아앗!! 하는 음성 과 함께 그 던전의 \\'강적\\'인 거대 섀도우가 나타난다.\\n또는 개소리\\n그러나 내비 전용 스킬인 뱀눈 노려보기(위험 감지와 같은 효과)와 채집 보조 스킬은 파티의 전투력에 전혀 지장을 주지 않으며, \\'대안심\\'을 달면 거의 볼 일이 없어져서 초중반 이후에는 존재감이 급격히 줄어든다.', 'contributors': '110.46.34.123,kirby10,max0243,218.54.117.149,ruby3141,121.165.63.239,iviyuki,1.229.200.194,anatra95,kiri47,175.127.134.2,nickchaos71,chkong1998,kiwitree2,namubot,huwieblusnow', 'namespace': ''}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"heegyu/namuwiki-extracted\" , cache_dir=\"/datasets/\")\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527501cd",
   "metadata": {},
   "source": [
    "2. 모델 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ab91c",
   "metadata": {},
   "source": [
    "| 구분         | 모델 (Model)                                          | 토크나이저 (Tokenizer)                                              |\n",
    "| ---------- | --------------------------------------------------- | -------------------------------------------------------------- |\n",
    "| **역할**     | 입력된 토큰을 기반으로 예측·생성·분류 등을 수행하는 핵심 AI 엔진              | 텍스트를 모델이 이해할 수 있는 토큰 단위로 변환하고, 반대로 토큰을 텍스트로 복원                 |\n",
    "| **입력/출력**  | 입력: 토큰 시퀀스<br>출력: 확률 분포, 다음 토큰, 임베딩 등               | 입력: 문자열<br>출력: 토큰 ID 시퀀스 및 주석 정보                               |\n",
    "| **구성 요소**  | 신경망(Transformer, LSTM, CNN 등), 레이어, 파라미터(가중치)로 이루어짐 | 규칙 기반(BPE, WordPiece, SentencePiece 등) 알고리즘과 단어 사전(Vocabulary) |\n",
    "| **학습 내용**  | 의미, 문맥, 패턴, 언어 구조 등을 학습                             | 자주 나타나는 텍스트 조각 단위를 효율적으로 분리하는 규칙을 학습                           |\n",
    "| **학습 대상**  | 대규모 텍스트의 문맥적 의미                                     | 텍스트의 통계적 구성(서브워드 단위 빈도 등)                                      |\n",
    "| **결과물**    | 문장 생성, 번역, 요약, 추론 등 자연어 처리 기능 수행                    | 토큰 리스트 생성 및 디토크나이징                                             |\n",
    "| **변경 영향**  | 모델 구조/파라미터 변경 시 성능에 직접적인 큰 변화 발생                    | 토크나이저 변경 시 토큰 분포가 바뀌어 모델 성능에 큰 영향 가능                           |\n",
    "| **독립성 여부** | 토크나이저가 만들어낸 토큰 단위에 의존해야 함                           | 모델 없이도 사용할 수 있지만 대부분 모델과 쌍으로 설계됨                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15beebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hugging Face 로그인 성공!\n",
      "모델 다운로드 중: meta-llama/Llama-4-Scout-17B-16E\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb982783a864fd6bdd1dda5fba798d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/237k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20e3e6938044205854987b0c8f63113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8294cbe2a7bd46f294a35af69b728fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/3.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65634d4844a4a62a36608421aabb6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8056262cb5044df292c2042b49773c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d49441409147b98f7016ed2f613e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/112k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcf2c9eafab4134993609d0adfb438d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ec09c70e29401eb9ca540298bdf6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8102e7a17cca498bace1ed4fd845f0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a49abcd83142fc934c287caf8c190e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f72496abf0c4dfa994162fb117e442f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00050.safetensors:   0%|          | 0.00/3.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239436dfbb1f463095bf4c6bef26388a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c07edcb684d4f228e628ffa3bed1d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05106f08df74157b0d506ed7113904b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdf4300a1d149f89abaeb7a6044c06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transformers 라이브러리를 사용한 모델 다운로드\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "model_name = \"meta-llama/Llama-4-Scout-17B-16E\"\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")  # 먼저 환경변수 확인\n",
    "if not hf_token:\n",
    "    print(\"Hugging Face 토큰을 입력하세요:\")\n",
    "    print(\"토큰 발급: https://huggingface.co/settings/tokens\")\n",
    "    hf_token = getpass(\"HF Token: \")\n",
    "\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"✅ Hugging Face 로그인 성공!\")\n",
    "else:\n",
    "    print(\"❌ 경고: 토큰이 입력되지 않았습니다.\")\n",
    "\n",
    "# 모델 다운로드\n",
    "print(f\"모델 다운로드 중: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"/models\", token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"/models\", token=hf_token)\n",
    "\n",
    "print(\"다운로드 완료!\")\n",
    "print(f\"Tokenizer: {tokenizer}\")\n",
    "print(f\"Model: {type(model)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
